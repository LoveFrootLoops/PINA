{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 1: Physics Informed Neural Networks on PINA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this tutorial we will show the typical use case of PINA on a toy problem. Specifically, the tutorial aims to introduce the following topics:\n",
    "\n",
    "* Defining a PINA Problem,\n",
    "* Build a `pinn` object,\n",
    "* Sample points in the domain.\n",
    "\n",
    "These are the three main steps needed **before** training a Physics Informed Neural Network (PINN). We will show in detailed each step, and at the end we will solve a very simple problem with PINA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PINA Problem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the Problem class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The problem definition in the PINA framework is done by building a phython `class`, inherited from one or more problem classes (`SpatialProblem`, `TimeDependentProblem`, `ParametricProblem`), depending on the nature of the problem treated. Let's see an example to better understand:\n",
    "#### Simple Ordinary Differential Equation\n",
    "Consider the following:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\frac{d}{dx}u(x) &=  u(x) \\quad x\\in(0,1)\\\\\n",
    "u(x=0) &= 1 \\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "with analytical solution $u(x) = e^x$. In this case we have that our ODE depends only on the spatial variable $x\\in(0,1)$ , this means that our problem class is going to be inherited from `SpatialProblem` class:\n",
    "\n",
    "```python\n",
    "from pina.problem import SpatialProblem\n",
    "from pina import Span\n",
    "\n",
    "class SimpleODE(SpatialProblem):\n",
    "    \n",
    "    output_variables = ['u']\n",
    "    spatial_domain = Span({'x': [0, 1]})\n",
    "\n",
    "    # other stuff ...\n",
    "```\n",
    "\n",
    "Notice that we define `output_variables` as a list of symbols, indicating the output variables of our equation (in this case only $u$). The `spatial_domain` variable indicates where the sample points are going to be sampled in the domain, in this case $x\\in(0,1)$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What about if we also have a time depencency in the equation? Well in that case our `class` will inherit from both `SpatialProblem` and `TimeDependentProblem`:\n",
    "```python\n",
    "from pina.problem import SpatialProblem, TimeDependentProblem\n",
    "from pina import Span\n",
    "\n",
    "class TimeSpaceODE(SpatialProblem, TimeDependentProblem):\n",
    "    \n",
    "    output_variables = ['u']\n",
    "    spatial_domain = Span({'x': [0, 1]})\n",
    "    temporal_domain = Span({'x': [0, 1]})\n",
    "\n",
    "    # other stuff ...\n",
    "```\n",
    "where we have included the `temporal_domain` variable indicating the time domain where we want the solution.\n",
    "\n",
    "Summarizing, in PINA we can initialize a problem with a class which is inherited from three base classes: `SpatialProblem`, `TimeDependentProblem`, `ParametricProblem`, depending on the type of problem we are considering. For reference:\n",
    "* `SpatialProblem` $\\rightarrow$ spatial variable(s) presented in the differential equation\n",
    "* `TimeDependentProblem` $\\rightarrow$ time variable(s) presented in the differential equation\n",
    "* `ParametricProblem` $\\rightarrow$ parameter(s) presented in the differential equation\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write the problem class\n",
    "\n",
    "Once the problem class is initialized we need to write the differential equation in PINA language. For doing this we need to load the pina operators found in `pina.operators` module. Let's again consider the Equation (1) and try to write the PINA model class:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from pina.problem import SpatialProblem\n",
    "from pina.operators import grad\n",
    "from pina import Condition, Span\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class SimpleODE(SpatialProblem):\n",
    "\n",
    "    output_variables = ['u']\n",
    "    spatial_domain = Span({'x': [0, 1]})\n",
    "\n",
    "    def ode_equation(input_, output_):\n",
    "        u_x = grad(output_, input_, components=['u'], d=['x'])\n",
    "        u = output_.extract(['u'])\n",
    "        return u_x - u\n",
    "\n",
    "    def ode_equation2(input_, output_):\n",
    "        u_x = grad(output_, input_, components=['u'], d=['x'])\n",
    "        u = output_.extract(['u'])\n",
    "        return u_x - u\n",
    "\n",
    "    def initial_condition(input_, output_):\n",
    "        value = 1.0\n",
    "        u = output_.extract(['u'])\n",
    "        return u - value\n",
    "\n",
    "    def initial_condition2(input_, output_):\n",
    "        value = 1.0\n",
    "        u = output_.extract(['u'])\n",
    "        return u - value\n",
    "\n",
    "    # Conditions to hold\n",
    "    conditions = {\n",
    "        'x0': Condition(location=Span({'x': 0.}), function=initial_condition),\n",
    "        'x01': Condition(location=Span({'x': 0.}), function=initial_condition2),\n",
    "        'D': Condition(location=Span({'x': [0, 1]}), function=ode_equation),\n",
    "        'D1': Condition(location=Span({'x': [0, 1]}), function=ode_equation2),\n",
    "        'D2': Condition(location=Span({'x': [0, 1]}), function=[ode_equation, ode_equation2])\n",
    "    }\n",
    "\n",
    "    # defining true solution\n",
    "    def truth_solution(self, pts):\n",
    "        return torch.exp(pts.extract(['x']))\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:33.240960500Z",
     "start_time": "2023-05-09T19:09:32.861909500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the defition of the Class we need to write different class methods, where each method is a function returning a residual. This functions are the ones minimized during the PINN optimization, for the different conditions. For example, in the domain $(0,1)$ the ODE equation (`ode_equation`) must be satisfied, so we write it by putting all the ODE equation on the right hand side, such that we return the zero residual. This is done for all the conditions  (`ode_equation`, `initial_condition`). \n",
    "\n",
    "Once we have defined the function we need to tell the network where these methods have to be applied. For doing this we use the class `Condition`. In `Condition` we pass the location points and the function to be minimized on those points (other possibilities are allowed, see the documentation for reference).\n",
    "\n",
    "Finally, it's possible to defing the `truth_solution` function, which can be useful if we want to plot the results and see a comparison of real vs expected solution. Notice that `truth_solution` function is a method of the `PINN` class, but it is not mandatory for the problem definition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build PINN object"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basics requirements for building a PINN model are a problem and a model. We have already covered the problem definition. For the model one can use the default models provided in PINA or use a custom model. We will not go into the details of model definition, Tutorial2 and Tutorial3 treat the topic in detail."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from pina.model import FeedForward\n",
    "from pina import PINN\n",
    "\n",
    "# initialize the problem\n",
    "problem = SimpleODE()\n",
    "\n",
    "# build the model\n",
    "model = FeedForward(\n",
    "    layers=[10, 10],\n",
    "    func=torch.nn.Tanh,\n",
    "    output_variables=problem.output_variables,\n",
    "    input_variables=problem.input_variables\n",
    ")\n",
    "\n",
    "# create the PINN object\n",
    "pinn = PINN(problem, model)\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:33.301548500Z",
     "start_time": "2023-05-09T19:09:32.945199600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the pinn object is fairly simple by using the `PINN` class, different optional inputs can be passed: optimizer, batch size, ... (see [documentation](https://mathlab.github.io/PINA/) for reference)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample points in the domain "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the `pinn` object is created, we need to generate the points for starting the optimization. For doing this we use the `span_pts` method of the `PINN` class.\n",
    "Let's see some methods to sample in $(0,1 )$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# sampling 20 points in (0, 1) with discrite step\n",
    "pinn.span_pts(20, 'grid', locations=['D'])\n",
    "\n",
    "# sampling 20 points in (0, 1) with latin hypercube\n",
    "pinn.span_pts(20, 'latin', locations=['D'])\n",
    "\n",
    "# sampling 20 points in (0, 1) randomly\n",
    "pinn.span_pts(20, 'random', locations=['D'])\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:33.317537600Z",
     "start_time": "2023-05-09T19:09:33.030835300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use a dictionary for specific variables:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pinn.span_pts({'variables': ['x'], 'mode': 'grid', 'n': 20}, locations=['D'])\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:33.318506300Z",
     "start_time": "2023-05-09T19:09:33.060756Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to use equispaced points for sampling. We need to sample in all the conditions domains. In our case we sample in `D` and `x0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# sampling for training\n",
    "pinn.span_pts(1, 'random', locations=['x0', 'x01'])\n",
    "pinn.span_pts(20, 'grid', locations=['D', 'D1', 'D2'])\n"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:33.318506300Z",
     "start_time": "2023-05-09T19:09:33.093668200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Very simple training and plotting\n",
    "\n",
    "Once we have defined the PINA model, created a network and sampled points in the domain, we have everything that is necessary for training a PINN. Here we show a very short training and some method for plotting the results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# simple training \n",
    "final_loss = pinn.train(stop=3000, frequency_print=1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sum          x0initial_co x01initial_c Dode_equatio D1ode_equati D2ode_equati D2ode_equati \n",
      "[epoch 00000] 3.053033e+00 1.507096e+00 1.482079e+00 1.845156e-02 1.629949e-02 2.910721e-02 \n",
      "              sum          x0initial_co x01initial_c Dode_equatio D1ode_equati D2ode_equati D2ode_equati \n",
      "[epoch 00001] 2.821522e+00 1.403268e+00 1.384566e+00 9.872204e-03 8.617212e-03 1.519928e-02 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# simple training \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m final_loss \u001B[38;5;241m=\u001B[39m \u001B[43mpinn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_print\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\pina\\pinn.py:270\u001B[0m, in \u001B[0;36mPINN.train\u001B[1;34m(self, stop, frequency_print, save_loss, trial)\u001B[0m\n\u001B[0;32m    267\u001B[0m         single_loss\u001B[38;5;241m.\u001B[39mappend(local_loss)\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 270\u001B[0m     \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msingle_loss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    273\u001B[0m losses\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28msum\u001B[39m(single_loss))\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\_tensor.py:478\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \n\u001B[0;32m    433\u001B[0m \u001B[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    475\u001B[0m \u001B[38;5;124;03m        used to compute the attr::tensors.\u001B[39;00m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhandle_torch_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mTensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    487\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    488\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    489\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\overrides.py:1551\u001B[0m, in \u001B[0;36mhandle_torch_function\u001B[1;34m(public_api, relevant_args, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1545\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1546\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be an error in future, please define it as a classmethod.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1547\u001B[0m                   \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[0;32m   1549\u001B[0m \u001B[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001B[39;00m\n\u001B[0;32m   1550\u001B[0m \u001B[38;5;66;03m# implementations can do equality/identity comparisons.\u001B[39;00m\n\u001B[1;32m-> 1551\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch_func_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpublic_api\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m   1554\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\_tensor.py:1295\u001B[0m, in \u001B[0;36mTensor.__torch_function__\u001B[1;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[0;32m   1292\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[1;32m-> 1295\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[0;32m   1297\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:193\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    189\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m \\\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28mtuple\u001B[39m(inputs) \u001B[38;5;28;01mif\u001B[39;00m inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m()\n\u001B[0;32m    192\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001B[38;5;28mlen\u001B[39m(tensors))\n\u001B[1;32m--> 193\u001B[0m grad_tensors_ \u001B[38;5;241m=\u001B[39m \u001B[43m_make_grads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_grads_batched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retain_graph \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n",
      "File \u001B[1;32m~\\PycharmProjects\\PINA\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:89\u001B[0m, in \u001B[0;36m_make_grads\u001B[1;34m(outputs, grads, is_grads_batched)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m out\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m     88\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad can be implicitly created only for scalar outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 89\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreserve_format\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     91\u001B[0m     new_grads\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T19:09:37.437789100Z",
     "start_time": "2023-05-09T19:09:33.124426400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the training we have saved the final loss in `final_loss`, which we can inspect. By default PINA uses mean square error loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# inspecting final loss\n",
    "final_loss\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By using the `Plotter` class from PINA we can also do some quatitative plots of the loss function. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pina.plotter import Plotter\n",
    "\n",
    "# plotting the loss\n",
    "plotter = Plotter()\n",
    "plotter.plot_loss(pinn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a very smooth loss decreasing!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "interpreter": {
   "hash": "56be7540488f3dc66429ddf54a0fa9de50124d45fcfccfaf04c4c3886d735a3a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
